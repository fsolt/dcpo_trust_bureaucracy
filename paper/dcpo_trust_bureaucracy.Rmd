---
output: 
  pdf_document:
    citation_package: natbib
    keep_tex: true
    fig_caption: true
    latex_engine: pdflatex
    template: svm-latex-ms2.tex
title: "[Trust in Bureaucracy]"
thanks: "Corresponding author: [frederick-solt@uiowa.edu](mailto:frederick-solt@uiowa.edu).  Current version: `r format(Sys.time(), '%B %d, %Y')`."
author:
- name: Yuehong 'Cassandra' Tai
  affiliation: Pennsylvania State University
- name: Frederick Solt
  affiliation: University of Iowa
anonymous: false
abstract: "[0/150 words]"
keywords: "xxxxx, political trust, measurement"
date: "`r format(Sys.time(), '%B %d, %Y')`"
fontsize: 11pt
spacing: double
bibliography: \dummy{`r file.path(getwd(), list.files(getwd(), ".bib$", recursive = TRUE))`}
# csl: https://raw.githubusercontent.com/citation-style-language/styles/master/american-political-science-association.csl
biblio-style: apsr
citecolor: black
linkcolor: black
endnote: no
header-includes:
      - \usepackage{array}
      - \usepackage{caption}
      - \usepackage{graphicx}
      - \usepackage{siunitx}
      - \usepackage{colortbl}
      - \usepackage{multirow}
      - \usepackage{hhline}
      - \usepackage{calc}
      - \usepackage{tabularx}
      - \usepackage{threeparttable}
      - \usepackage{wrapfig}
---

```{r setup, include=FALSE}
options(tinytex.verbose = TRUE)

knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE,
                      fig.width=7, fig.height=2.5)

# If `DCPOtools` is not yet installed:
# remotes::install_github("fsolt/DCPOtools")

library(DCPOtools)
library(tidyverse)
library(cmdstanr)
library(countrycode)
library(patchwork)
library(rsdmx)
library(osfr)

set.seed(324)
```

Intro

```{r dcpo_input_raw, include=FALSE, cache = TRUE, cache.extra = tools::md5sum(here::here("data-raw", "surveys_bureaucracy.csv"))}
surveys_tb <- read_csv(here::here("data-raw", "surveys_bureaucracy.csv"),
                       col_types = "cccccc")

dcpo_input_raw <- DCPOtools::dcpo_setup(vars = surveys_tb,
                                        datapath = here::here("..",
                                                              "data", "dcpo_surveys"),
                                        file = here::here("data",
                                                          "dcpo_input_raw.csv"))
```

```{r tb_summary_stats, cache = TRUE, cache.extra = tools::md5sum(here::here("data-raw", "dcpo_input_raw.csv"))}
dcpo_input_raw <- read_csv(here::here("data", "dcpo_input_raw.csv"),
                                  col_types = "cdcddcd")

process_dcpo_input_raw <- function(dcpo_input_raw_df) {
  dcpo_input_raw_df %>% 
    with_min_yrs(2) %>% 
    with_min_cy(5) %>% 
    with_min_yrs(2) %>% 
    filter(year >= 1972 & n > 0) %>% 
    group_by(country) %>% 
    mutate(cc_rank = n()) %>% 
    ungroup() %>% 
    arrange(-cc_rank)
}

dcpo_input_raw1 <- dcpo_input_raw %>% 
  process_dcpo_input_raw()

n_surveys <- surveys_tb %>% 
  distinct(survey) %>% 
  nrow()

n_items <- dcpo_input_raw1 %>%
  distinct(item) %>% 
  nrow()

n_countries <- dcpo_input_raw1 %>%
  distinct(country) %>% 
  nrow()

n_cy <- dcpo_input_raw1 %>%
  distinct(country, year) %>% 
  nrow() %>% 
  scales::comma()

n_years <- as.integer(summary(dcpo_input_raw1$year)[6]-summary(dcpo_input_raw1$year)[1])

spanned_cy <- dcpo_input_raw %>% 
  group_by(country) %>% 
  summarize(years = max(year) - min(year) + 1) %>% 
  summarize(n = sum(years)) %>% 
  pull(n) %>% 
  scales::comma()

total_cy <- {n_countries * n_years} %>% 
  scales::comma()

year_range <- paste("from",
                    summary(dcpo_input_raw$year)[1],
                    "to",
                    summary(dcpo_input_raw$year)[6])

n_cyi <- dcpo_input_raw1 %>% 
  distinct(country, year, item) %>% 
  nrow() %>% 
  scales::comma()

back_to_numeric <- function(string_number) {
  string_number %>% 
    str_replace(",", "") %>% 
    as.numeric()
}

covered_share_of_spanned <- {back_to_numeric(n_cy)/back_to_numeric(spanned_cy) * 100}
```

In this letter, we present the trust in civil servants (TCS) dataset, which is based on the host of national and cross-national survey data available and recent advances in latent variable modeling of public opinion that allow us to make use of this sparse and incomparable data.
It provides comparable estimates of the trust and confidence the public puts in civil servants and public administrators across countries and over time.
We validate the data by showing that these TCS scores are strongly correlated with responses to single survey items as well as with measures of [women's participation in the workforce and in the boardroom].
We expect that the TCS data will become an invaluable source for broadly cross-national and longitudinal research on the causes and effects of trust in the civil service.


# Examining the Source Data on Trust in Bureaucracy

National and cross-national surveys have often included questions tapping attitudes toward equality for women and men in the public sphere over the past half-century, but the resulting data are both sparse, that is, unavailable for many countries and years, and incomparable, generated by many different survey items.
In all, we identified `r n_items` such survey items that were asked in no fewer than five country-years in countries surveyed at least twice; these items were drawn from `r n_surveys` different survey datasets.^[
The complete list of trust in civil servants survey items is included in online Appendix A.]
Together, the survey items in the source data were asked in `r n_countries` different countries in at least two time points over `r n_years` years, `r year_range`, yielding a total of `r n_cyi` country-year-item observations.
Observations for every year in each country surveyed would number `r total_cy`, and a complete set of country-year-items would encompass `r {n_countries * n_years * n_items} %>% scales::comma()` observations.
Compared to this complete set of country-year-items, the available data can be seen to be very, very sparse.
From a more optimistic standpoint, we note there there are `r n_cy` country-years in which we have at least _some_ information about the trust in civil servants of the population, that is, some `r round(covered_share_of_spanned)`% of the `r spanned_cy` country-years spanned by the data we collected.
But there can be no denying that the many different survey items employed renders these data incomparable and difficult to use together.

```{r item_and_country_plots, fig.height = 3.5, fig.cap = "Countries and Years with the Most Observations in the TCS Source Data \\label{item_country_plots}"}
items_plot <- dcpo_input_raw1 %>%
  distinct(country, year, item) %>%
  count(item) %>%
  arrange(desc(n)) %>% 
  # head(12) %>% 
  ggplot(aes(forcats::fct_reorder(item, n, .desc = TRUE), n)) +
  geom_bar(stat = "identity") +
  theme_bw() +
  theme(axis.title.x = element_blank(),
        axis.text.x  = element_text(angle = 90, vjust = .45, hjust = .95),
        axis.title.y = element_text(size = 9),
        plot.title = element_text(hjust = 0.5, size = 11)) +
  ylab("Country-Years\nObserved") +
  ggtitle("Items")

trust4_cy <- dcpo_input_raw1 %>% 
  filter(item == "trust4") %>%
  distinct(country, year) %>%
  nrow()

trust4_surveys <- dcpo_input_raw1 %>%
  filter(item == "trust4") %>%
  distinct(survey) %>%
  pull(survey) %>% 
  str_split(", ") %>% 
  unlist() %>% 
  unique() %>% 
  sort()


countries_plot <- dcpo_input_raw1 %>%
  mutate(country = if_else(stringr::str_detect(country, "United"),
                           stringr::str_replace(country, "((.).*) ((.).*)", "\\2.\\4."),
                           country)) %>% 
  distinct(country, year, item) %>% 
  count(country) %>%
  arrange(desc(n)) %>% 
  head(12) %>% 
  ggplot(aes(forcats::fct_reorder(country, n, .desc = TRUE), n)) +
  geom_bar(stat = "identity") +
  theme_bw() +
  theme(axis.title.x = element_blank(),
        axis.text.x  = element_text(angle = 90, vjust = .45, hjust = .95),
        axis.title.y = element_text(size = 9),
        plot.title = element_text(hjust = 0.5, size = 11)) +
  ylab("Year-Items\nObserved") +
  ggtitle("Countries")

cby_plot <- dcpo_input_raw1 %>%
  mutate(country = if_else(stringr::str_detect(country, "United"),
                           stringr::str_replace(country, "((.).*) ((.).*)", "\\2.\\4."),
                           country),
         country = stringr::str_replace(country, "South", "S.")) %>% 
  distinct(country, year) %>%
  count(country) %>% 
  arrange(desc(n)) %>% 
  head(12) %>% 
  ggplot(aes(forcats::fct_reorder(country, n, .desc = TRUE), n)) +
  geom_bar(stat = "identity") +
  theme_bw() +
  theme(axis.title.x = element_blank(),
        axis.text.x  = element_text(angle = 90, vjust = .45, hjust = .95),
        axis.title.y = element_text(size = 9),
        plot.title = element_text(hjust = 0.5, size = 11)) +
  ylab("Years\nObserved") +
  ggtitle("Countries")


ybc_plot <- dcpo_input_raw1 %>%
  distinct(country, year) %>%
  count(year, name = "nn") %>%
  ggplot(aes(year, nn)) +
  geom_bar(stat = "identity") +
  theme_bw() +
  theme(axis.title.x = element_blank(),
        # axis.text.x  = element_text(angle = 90, vjust = .45, hjust = .95),
        axis.title.y = element_text(size = 9),
        plot.title = element_text(hjust = 0.5, size = 11)) +
  ylab("Countries\nObserved") +
  ggtitle("Years")

us_obs <- dcpo_input_raw1 %>% 
  distinct(country, year, item) %>%
  count(country) %>%
  filter(country == "United States") %>%
  pull(n)

others <- dcpo_input_raw1 %>%
  distinct(country, year, item) %>%
  count(country) %>%
  arrange(desc(n)) %>%
  slice(2:5) %>%
  pull(country) %>% 
  knitr::combine_words()

countries_cp <- dcpo_input_raw1 %>%
  mutate(country = if_else(stringr::str_detect(country, "United"),
                           stringr::str_replace(country, "((.).*) ((.).*)", "\\2.\\4."),
                           country),
         country = stringr::str_replace(country, "South", "S.")) %>% 
  distinct(country, year, item) %>%
  count(country) %>% 
  arrange(desc(n)) %>% 
  head(12) %>% 
  pull(country)

countries_cbyp <- dcpo_input_raw1 %>%
  mutate(country = if_else(stringr::str_detect(country, "United"),
                           stringr::str_replace(country, "((.).*) ((.).*)", "\\2.\\4."),
                           country),
         country = stringr::str_replace(country, "South", "S.")) %>% 
  distinct(country, year) %>%
  count(country) %>% 
  arrange(desc(n)) %>% 
  head(12) %>% 
  pull(country)

adding <- setdiff(countries_cbyp, countries_cp) %>% 
  knitr::combine_words()

dropping <- setdiff(countries_cp, countries_cbyp) %>% 
  knitr::combine_words()

y_peak_year <- dcpo_input_raw1 %>%
  distinct(country, year) %>%
  count(year, name = "nn") %>% 
  filter(nn == max(nn)) %>% 
  pull(year)

y_peak_nn <- dcpo_input_raw1 %>%
  distinct(country, year) %>%
  count(year, name = "nn") %>% 
  filter(nn == max(nn)) %>% 
  pull(nn)

data_poorest <- dcpo_input_raw1 %>%
  distinct(country, year, item) %>%
  count(country) %>%
  arrange(n) %>%
  filter(n == 2) %>%
  pull(country) %>% 
  knitr::combine_words() %>% 
  paste0("---", ., "---")

wordify_numeral <- function(x) setNames(c("one", "two", "three", "four", "five", "six", "seven", "eight", "nine", "ten", "eleven", "twelve", "thirteen", "fourteen", "fifteen", "sixteen", " seventeen", "eighteen", "nineteen"), 1:19)[x]

n_data_poor <- {data_poorest %>%
    str_split(",") %>% 
    first()} %>% 
  length() 

  if(n_data_poor < 20) {
    n_data_poorest <- n_data_poor %>% 
      wordify_numeral()
  } else {
    n_data_poorest <- n_data_poor
    data_poorest <- " "
  }

(countries_plot + cby_plot) / (ybc_plot)
```

\pagebreak
```{r obs_by_cy, fig.height = 9, fig.width = 6.5, fig.cap = "Source Data Observations by Country and Year \\label{obs_by_cy}"}
dcpo_input_raw1 %>% 
  mutate(country = str_replace(country, "’", "'")) %>% 
  distinct(country, year, item, cc_rank) %>% 
  group_by(country, year) %>% 
  summarize(n = n(),
            cc_rank = cc_rank) %>% 
  ungroup() %>% 
  distinct() %>% 
  ggplot(aes(x = year, 
             y = forcats::fct_reorder(country, cc_rank),
             fill = n)) + 
  geom_tile() +
  scale_fill_stepsn(colors = rev(hcl.colors(5, "inferno")),
                    n.breaks = 5,
                    show.limits = TRUE,
                    right = FALSE,
                    name = "Observations") +
  labs(x = NULL, y = NULL) +
  scale_x_continuous(breaks=seq(1972, 2020, 4),
                     sec.axis = dup_axis()) +
  scale_y_discrete(position = "right") +
  theme(legend.justification=c(0, 0), 
        legend.position=c(0.01, 0.01),
        axis.text.y  = element_text(size = 7)) 
```


Consider the most frequently asked item in the data we collected, which asks respondents whether they strongly agree, agree, disagree, or strongly disagree with the statement "I am going to name a number of institutions. For each one, could you tell me how much trust you have in them. Is it a great deal of trust, some trust, not very much trust or none at all? Civil service."^[Question text may vary slightly across survey datasets, but not, roughly speaking, by more than the translation differences across languages found within the typical cross-national survey dataset. In this case, some questions ask about "the public administration" or "government officials" rather than "the civil service," and some refer to "confidence" rather than "trust."  These words are often translated identically.]
Employed by the Arab Barometer, the Asia Europe Survey, the Asian Barometer, the British Social Attitudes Survey, the East Asian Social Survey, the European Values Survey, the Italian National Election Study, the South Asian Barometer, and the World Values Survey, this question was asked in a total of `r trust4_cy` different country-years.
That this constitutes only `r {trust4_cy*100/(spanned_cy %>% str_replace(",", "") %>% as.numeric())} %>% round()`% of the country-years spanned by our data---and again, this is the _most common_ survey item---again underscores just how sparse and incomparable the available public opinion data is on this topic.

The upper left panel of Figure&nbsp;\ref{item_country_plots} shows the dozen countries with the highest count of country-year-item observations.
The United States, with `r us_obs` observations, is far and away the best represented country in the source data, followed by `r others`.
At the other end of the spectrum, `r n_data_poorest` countries`r data_poorest`have only the minimum two observations required to be included in the source dataset at all.
The upper right panel shows the twelve countries with the most years observed; this group is similar, but with `r adding` joining the list and `r dropping` dropping off.
The bottom panel counts the countries observed in each year and reveals just how few relevant survey items were asked before 1990.
Country coverage reached its peak in `r y_peak_year`, when respondents in `r y_peak_nn` countries were asked items about trust in civil servants.
In the next section, we describe how we are able to make use of all of this sparse and incomparable survey data to generate complete, comparable time-series TCS scores using a latent variable model.

```{r dcpo_input}
dcpo_input <- DCPOtools::format_dcpo(dcpo_input_raw1,
                                     scale_q = "trust4",
                                     scale_cp = 2)
save(dcpo_input, file = here::here("data", "dcpo_input.rda"))
```

# Estimating trust in civil servants

A number of recent studies have developed latent variable models of public opinion based on cross-national survey data [see @Claassen2019; @Caughey2019; @McGann2019; @Kolczynska2020].
To estimate trust in civil servants across countries and over time, we employ the latest of these methods that is appropriate for data that is not only incomparable but also sparse, the Dynamic Comparative Public Opinion (DCPO) model elaborated in @Solt2020c.^[
@Solt2020c demonstrates that the DCPO model provides a better fit to survey data than the models put forward by @Claassen2019 or @Caughey2019.
The @McGann2019 model depends on dense survey data unlike the sparse data on trust in civil servants described in the preceding section.
@Kolczynska2020 is the very most recent of these five works and builds on each of the others, but the MRP approach developed in that piece is suitable not only when the available survey data are dense but also when ancillary data on population characteristics are available, so it is similarly inappropriate to this application.]
The DCPO model is a population-level two-parameter ordinal logistic item response theory (IRT) model with country-specific item-bias terms.
For a detailed description of the DCPO model, see Appendix B and @Solt2020c [, 3-8]; here, we focus on how it deals with the principal issues raised by our source data, incomparability and sparsity.

The DCPO model accounts for the incomparability of different survey questions with two parameters.
First, it incorporates the _difficulty_ of each question's responses, that is, how much trust in civil servants is indicated by a given response. 
That each response evinces more or less of our latent trait is most easily seen with regard to the ordinal responses to the same question: strongly agreeing with the statement "you can generally trust the people who run our government to do what is right," exhibits more trust in civil servants than responding "agree," which in turn is more trusting than responding "disagree," which is a more trusting response than "strongly disagree."
But this is also true across questions.
For example, expressing "great trust" in civil servants "to look after your interests" likely expresses even more trust than just strongly agreeing that civil servants can be trusted to do what is right.
Second, the DCPO model accounts for each question's _dispersion_, its noisiness with regard to our latent trait.
The lower a question's dispersion, the better that changes in responses to the question map onto changes in trust of civil servants.
Together, the model's difficulty and dispersion estimates work to generate comparable estimates of the latent variable of trust in civil servants from the available but incomparable source data.

To address the sparsity of the source data---the fact that there are gaps in the time series of each country, and even many observed country-years have only one or few observed items---DCPO uses simple local-level dynamic linear models, i.e., random-walk priors, for each country.
That is, within each country, each year's value of trust in civil servants is modeled as the previous year's estimate plus a random shock.
These dynamic models smooth the estimates of trust in civil servants over time and allow estimation even in years for which little or no survey data is available, albeit at the expense of greater measurement uncertainty.

```{r dcpo_chunk_options}
evaluate <- TRUE
```


```{r dcpo, eval=evaluate, cache=evaluate, include=FALSE, results=FALSE}
iter <- 1000

dcpo <- cmdstan_model("~/Documents/Projects/DCPO/inst/stan/dcpo.stan")
dcpo_output <- dcpo$sample(
  data = dcpo_input[1:13], 
  max_treedepth = 14,
  adapt_delta = 0.99,
  step_size = 0.005,
  seed = 324, 
  chains = 4, 
  parallel_chains = 4,
  iter_warmup = iter/2,
  iter_sampling = iter/2,
  refresh = iter/50
)
results_path <- here::here(file.path("data", 
                                     iter, 
                                     {str_replace_all(Sys.time(), "[- :]", "") %>%
                                         str_replace("\\d{2}$", "")}))
dir.create(results_path, 
           showWarnings = FALSE, 
           recursive = TRUE)
dcpo_output$save_data_file(dir = results_path,
                           random = FALSE)
dcpo_output$save_output_files(dir = results_path,
                              random = FALSE)
```

```{r dcpo_results, cache=TRUE}
if (!exists(results_path)) {
  latest <- "202203210942"
  results_path <- here::here("data", "1000", latest)
  
  # Define OSF_PAT in .Renviron: https://docs.ropensci.org/osfr/articles/auth
  if (!file.exists(file.path(results_path, paste0("dcpo-", latest, "-1.csv")))) {
    dir.create(results_path, showWarnings = FALSE, recursive = TRUE)
    osf_retrieve_node("82w36") %>% 
      osf_ls_files() %>% 
      filter(name == latest) %>% 
      osf_download(path = here::here("data", "1000"))
  }
}

dcpo_output <- as_cmdstan_fit(here::here(results_path,
                                         list.files(results_path, pattern = "csv$")))

load(file = here::here("data", "dcpo_input.rda"))
```

```{r dcpo_results_summary, cache=TRUE}
theta_results <- DCPOtools::summarize_dcpo_results(dcpo_input,
                                                   dcpo_output,
                                                   "theta")

res_cy <- nrow(theta_results) %>% 
  scales::comma()

res_c <- theta_results %>% 
  pull(country) %>% 
  unique() %>% 
  length()
```


```{r cs_plot, fig.cap="TCS Scores, Most Recent Available Year \\label{cs_mry}", fig.height=10, fig.width=8}

n_panes <- 2
axis_text_size <- 10

p1_data <- theta_results %>%
  group_by(country) %>%
  top_n(1, year) %>%
  ungroup() %>%
  arrange(mean) %>%
  transmute(country_year = paste0(country, " (", year, ")") %>% 
              str_replace("’", "'"),
            estimate = mean,
            conf.high = q90,
            conf.low = q10,
            pane = n_panes - (ntile(mean, n_panes) - 1),
            ranked = as.factor(ceiling(row_number())))

p_theta <- ggplot(p1_data,
                  aes(x = estimate, y = ranked)) +
  geom_segment(aes(x = conf.low, xend = conf.high,
                   y = ranked, yend = ranked),
               na.rm = TRUE,
               alpha = .4) +
  geom_point(fill = "black", shape = 21, size = .5, na.rm = TRUE) +
  theme_bw() + theme(legend.position="none",
                     axis.text.x  = element_text(size = axis_text_size,
                                                 angle = 90,
                                                 vjust = .45,
                                                 hjust = .95),
                     axis.text.y  = element_text(size = axis_text_size),
                     axis.title = element_blank(),
                     strip.background = element_blank(), 
                     strip.text = element_blank(),
                     panel.grid.major = element_line(size = .3),
                     panel.grid.minor = element_line(size = .15)) +
  scale_y_discrete(breaks = p1_data$ranked, labels=p1_data$country_year) +
  coord_cartesian(xlim=c(0, 1)) +
  facet_wrap(vars(pane), scales = "free", nrow = 1)


p_theta +
  plot_annotation(caption = "Note: Gray whiskers represent 80% credible intervals.")

bottom5 <- p1_data %>% 
  arrange(ranked) %>% 
  slice(1:5) %>% 
  pull(country_year) %>% 
  str_replace(" \\(.*", "") %>% 
  knitr::combine_words()

```

We estimated the model using the `DCPOtools` package for R [@Solt2020a], running four chains for 1,000 iterations each and discarding the first half as warmup, which left us with 2,000 samples.
The $\hat{R}$ diagnostic had a maximum value of 1.02, indicating that the model converged.

The dispersion parameters of the survey items indicate that all of them load well on the latent variable (see Appendix A).
The result is estimates, in all `r res_cy` country-years spanned by the source data, of mean public gender egalitarianism, what we call TCS scores.
Figure&nbsp;\ref{cs_mry} displays the most recent available TCS score for each of the `r res_c` countries and territories in the dataset.

[The Scandinavian countries and France are at the top of this list, along with Puerto Rico, which has had women of both of its major parties serve as chief executive and as recently as 2020 had a woman from each party holding the two most prominent elected offices on the island.]
The latest scores for `r bottom5` have them as the places where public opinion is least favorable to gender equality in the public sphere.

```{r ts_plots, fig.cap="TCS Scores Over Time Within Selected Countries \\label{ts}", fig.height=3.5}
countries <- c("Finland", "China", "Philippines", "Bangladesh",
               "Malaysia", "Turkey", "United Kingdom", "South Korea",
               "Belgium", "Spain", "United States", "Chile", 
               "Ukraine", "Italy", "Argentina", "Mexico")

countries2 <- countries %>% 
  str_replace("United States", "U.S.") %>% 
  str_replace("United Kingdom", "U.K.")

alpha_results <- DCPOtools::summarize_dcpo_results(dcpo_input,
                                                   dcpo_output,
                                                   "alpha")

c_rawdata <- dcpo_input$data %>% 
  filter(country %in% countries) %>%
  mutate(mean = y_r/n_r,
         country = str_replace(country, "United States", "U.S.") %>% 
           str_replace("United Kingdom", "U.K.") %>% 
           factor(levels = countries2)) %>% 
  left_join(alpha_results %>% select(question, alpha_mean = mean), by = "question")

c_res <- theta_results %>% 
  filter(country %in% countries) %>%
  mutate(country = str_replace(country, "United States", "U.S.") %>% 
           str_replace("United Kingdom", "U.K.") %>% 
           factor(levels = countries2))

ggplot(data = c_rawdata, aes(x = year, y = mean)) +
  geom_line(aes(color = item, alpha = 1/alpha_mean)) +
  geom_point(aes(color = item, alpha = 1/alpha_mean)) +
  theme_bw() +
  theme(legend.position = "none") +
  coord_cartesian(xlim = c(1980, 2020), ylim = c(0, 1)) +
  labs(x = NULL, y = "TCS Scores") +
  geom_ribbon(data = c_res, aes(ymin = q10, ymax = q90, linetype=NA), alpha = .25) +
  geom_line(data = c_res) +
  facet_wrap(~country, nrow = 2) +
  theme(axis.text.x  = element_text(size=7,
                                    angle = 90,
                                    vjust = .45,
                                    hjust = .95),
        strip.background = element_rect(fill = "white", colour = "white")) +
  plot_annotation(caption = "Note: Countries are ordered by their TCS scores in their most recent\navailable year; gray shading represents 80% credible intervals.")
```



\pagebreak
\pagebreak
# Appendix A: Survey Items Used to Estimate Trust in Civil Servants
National and cross-national surveys have often included questions tapping attitudes toward equality for women and men in the public sphere over the past half-century, but the resulting data are both sparse, that is, unavailable for many countries and years, and incomparable, generated by many different survey items.
In all, we identified `r n_items` such survey items that were asked in no fewer than five country-years in countries surveyed at least twice; these items were drawn from `r n_surveys` different survey datasets.
These items are listed in the table below, along with the dispersion ($\alpha$) and difficulty ($\beta$) scores estimated for each from the DCPO model.
Question text may vary slightly across survey datasets, but not, roughly speaking, by more than the translation differences across languages found within the typical cross-national survey dataset.
Lower values of dispersion indicate questions that better identify publics with more public gender egalitarianism from those with less.
Items have one less difficulty score than the number of response categories.
Survey dataset codes correspond to those used in the `DCPOtools` R package; they appear in decreasing order of country-years contributed.

Together, the survey items in the source data were asked in `r n_countries` different countries in at least two time points over `r n_years` years, `r year_range`, yielding a total of `r n_cyi` country-year-item observations.
The number of items observed in the source data for each country-year is plotted in Figure \ref{obs_by_cy} below.
The TCS scores of country-years with more observed items are likely to be estimated more precisely.
The estimates for country-years with fewer (or no) observed items rely more heavily (or entirely) on the random-walk prior and are therefore less certain.
Figure \ref{obs_by_item2} displays the distribution of the source data in yet another way, showing the (binned) number of country-years in which both members of each pair of items is observed.



# Appendix B: The DCPO Model
A number of recent studies have developed latent variable models of public opinion based on cross-national survey data [see @Claassen2019; @Caughey2019; @McGann2019; @Kolczynska2020].
To estimate trust in civil servants across countries and over time, we employ the latest of these methods that is appropriate for data that is not only incomparable but also sparse, the Dynamic Comparative Public Opinion (DCPO) model elaborated in @Solt2020c.^[
@Solt2020c demonstrates that the DCPO model provides a better fit to survey data than the models put forward by @Claassen2019 or @Caughey2019.
The @McGann2019 model depends on dense survey data unlike the sparse data on trust in civil servants described in the preceding section.
@Kolczynska2020 is the very most recent of these five works and builds on each of the others, but the MRP approach developed in that piece is suitable not only when the available survey data are dense but also when ancillary data on population characteristics are available, so it is similarly inappropriate to this application.]
The DCPO model is a population-level two-parameter ordinal logistic item response theory (IRT) model with country-specific item-bias terms.

DCPO models the total number of survey responses expressing at least as much trust in civil servants as response category $r$ to each question $q$ in country $k$ at time $t$, $y_{ktqr}$, out of the total number of respondents surveyed, $n_{ktqr}$, using the beta-binomial distribution:

\begin{equation}
a_{ktqr} = \phi\eta_{ktqr} \label{eq:bb_a}
\end{equation}
\begin{equation}
b_{ktqr} = \phi(1 - \eta_{ktqr}) \label{eq:bb_b}
\end{equation}
\begin{equation}
y_{ktqr} \sim \textrm{BetaBinomial}(n_{ktqr}, a_{ktqr}, b_{ktqr}) \label{eq:betabinomial}
\end{equation}

where $\phi$ represents an overall dispersion parameter to account for additional sources of survey error beyond sampling error and $\eta_{ktqr}$ is the expected probability that a random person in country $k$ at time $t$ answers question $q$ with a response at least as positive as response $r$.^[
The ordinal responses to question $q$ are coded to range from 1 (expressing the least trust in civil servants) to $R$ (expressing the most trust in civil servants), and $r$ takes on all values greater than 1 and less than or equal to $R$.]

This expected probability, $\eta_{ktqr}$, is in turn estimated as follows:

\begin{equation}
\eta_{ktqr} = \textrm{logit}^{-1}(\frac{\bar{\theta'}_{kt} - (\beta_{qr} + \delta_{kq})}{\sqrt{\alpha_{q}^2 + (1.7*\sigma_{kt})^2}}) \label{eq:dcpo}
\end{equation}

In this equation, $\beta_{qr}$ represents the difficulty of response $r$ to question $q$, that is, the degree of trust in civil servants the response expresses.  The $\delta_{kq}$ term represents country-specific item bias: the extent to which all responses to a particular question $q$ may be more (or less) difficult in a given country $k$ due to translation issues, cultural differences in response styles, or other idiosyncrasies that render the same survey item not equivalent across countries.^[
Estimating $\delta_{kq}$ requires repeated administrations of question $q$ in country $k$, so
when responses to question $q$ are observed in country $k$ in only a single year, the DCPO model sets $\delta_{kq}$ to zero by assumption, increasing the error of the model by any country-item bias that is present.
Questions that are asked repeatedly over time in only a single country pose no risk of country-specific item bias, so $\delta_{kq}$ in such cases are also set to zero.]
The dispersion of question $q$, its noisiness in relation to our latent variable, is $\alpha_{q}$. The mean and standard deviation of the unbounded latent trait of trust in civil servants are $\bar{\theta'}_{kt}$ and $\sigma_{kt}$, respectively.

Random-walk priors are used to account for the dynamics in $\bar{\theta'}_{kt}$ and $\sigma_{kt}$, and weakly informative priors are placed on the other parameters.^[
The dispersion parameters $\alpha_{q}$ are drawn from standard half-normal prior distributions, that is, the positive half of N(0, 1).
The first difficulty parameters for each question, $\beta_{q1}$, are drawn from standard normal prior distributions, and the differences between $\beta$s for each $r$ for the same question $q$ are drawn from standard half-normal prior distributions.
The item-bias parameters $\delta_{kq}$ receive normally-distributed hierarchical priors with mean 0 and standard deviations drawn from standard half-normal prior distributions.
The initial value of the mean unbounded latent trait for each country, $\bar{\theta'}_{k1}$, is assigned a standard normal prior, as are the transition variances $\sigma_{\bar{\theta'}}^2$ and $\sigma_{\sigma}^2$; the initial value of the standard deviation of the unbounded latent trait for each country, $\sigma_{k1}$, is drawn from a standard lognormal prior distribution.
The overall dispersion, $\phi$, receives a somewhat more informative prior drawn from a gamma(4, 0.1) distribution that yields values that are well scaled for that parameter.]
The dispersion parameters $\alpha_q$ are constrained to be positive and all survey responses are coded with high values indicating more trust in civil servants to fix direction.
The difficulty $\beta$ of "disagree" (on the four-point, "strongly agree" to "strongly disagree" scale) to the statement "On the whole, men make better political leaders than women do" is set to 1 to identify location, and for each question $q$ the difficulties for increasing response categories $r$ are constrained to be increasing.
The sum of $\delta_{kq}$ across all countries $k$ is set to zero for each question $q$:

\begin{equation}
\sum_{k = 1}^K \delta_{kq} = 0
\end{equation}

Finally, the logistic function is used to transform $\bar{\theta'}_{kt}$ to the unit interval and so give the bounded mean of latent trust in civil servants, $\bar{\theta}_{kt}$, which is our parameter of interest here [see @Solt2020c, 3-8].


The DCPO model accounts for the incomparability of different survey questions with two parameters.
First, it incorporates the _difficulty_ of each question's responses, that is, how much trust in civil servants is indicated by a given response. 
That each response evinces more or less of our latent trait is most easily seen with regard to the ordinal responses to the same question: strongly agreeing with the statement "both the husband and wife should contribute to household income," exhibits more trust in civil servants than responding "agree," which in turn is more egalitarian than responding "disagree," which is a more egalitarian response than "strongly disagree."
But this is also true across questions.
For example, strongly disagreeing that "on the whole, men make better business executives than women do" likely expresses even more egalitarianism than strongly agreeing merely that both spouses should have paying jobs.
Second, the DCPO model accounts for each question's _dispersion_, its noisiness with regard to our latent trait.
The lower a question's dispersion, the better that changes in responses to the question map onto changes in trust in civil servants.
Together, the model's difficulty and dispersion estimates work to generate comparable estimates of the latent variable of trust in civil servants from the available but incomparable source data.

To address the sparsity of the source data---the fact that there are gaps in the time series of each country, and even many observed country-years have only one or few observed items---DCPO uses simple local-level dynamic linear models, i.e., random-walk priors, for each country.
That is, within each country, each year's value of trust in civil servants is modeled as the previous year's estimate plus a random shock.
These dynamic models smooth the estimates of trust in civil servants over time and allow estimation even in years for which little or no survey data is available, albeit at the expense of greater measurement uncertainty.